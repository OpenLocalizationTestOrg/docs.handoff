{"content":"---\ntitle: \"When to Use a Thread-Safe Collection\"\nms.date: \"03/30/2017\"\nms.technology: dotnet-standard\nhelpviewer_keywords: \n  - \"thread-safe collections, when to upgrade\"\nms.assetid: a9babe97-e457-4ff3-b528-a1bc940d5320\nauthor: \"mairaw\"\nms.author: \"mairaw\"\n---\n# When to Use a Thread-Safe Collection\nThe [!INCLUDE[net_v40_long](../../../../includes/net-v40-long-md.md)] introduces five new collection types that are specially designed to support multi-threaded add and remove operations. To achieve thread-safety, these new types use various kinds of efficient locking and lock-free synchronization mechanisms. Synchronization adds overhead to an operation. The amount of overhead depends on the kind of synchronization that is used, the kind of operations that are performed, and other factors such as the number of threads that are trying to concurrently access the collection.  \n  \n In some scenarios, synchronization overhead is negligible and enables the multi-threaded type to perform significantly faster and scale far better than its non-thread-safe equivalent when protected by an external lock. In other scenarios, the overhead can cause the thread-safe type to perform and scale about the same or even more slowly than the externally-locked, non-thread-safe version of the type.  \n  \n The following sections provide general guidance about when to use a thread-safe collection versus its non-thread-safe equivalent that has a user-provided lock around its read and write operations. Because performance may vary depending on many factors, the guidance is not specific and is not necessarily valid in all circumstances. If performance is very important, then the best way to determine which collection type to use is to measure performance based on representative computer configurations and loads. This document uses the following terms:  \n  \n *Pure producer-consumer scenario*  \n Any given thread is either adding or removing elements, but not both.  \n  \n *Mixed producer-consumer scenario*  \n Any given thread is both adding and removing elements.  \n  \n *Speedup*  \n Faster algorithmic performance relative to another type in the same scenario.  \n  \n *Scalability*  \n The increase in performance that is proportional to the number of cores on the computer. An algorithm that scales performs faster on eight cores than it does on two cores.  \n  \n## ConcurrentQueue(T) vs. Queue(T)  \n In pure producer-consumer scenarios, where the processing time for each element is very small (a few instructions), then <xref:System.Collections.Concurrent.ConcurrentQueue%601?displayProperty=nameWithType> can offer modest performance benefits over a <xref:System.Collections.Generic.Queue%601?displayProperty=nameWithType> that has an external lock. In this scenario, <xref:System.Collections.Concurrent.ConcurrentQueue%601> performs best when one dedicated thread is queuing and one dedicated thread is de-queuing. If you do not enforce this rule, then <xref:System.Collections.Generic.Queue%601> might even perform slightly faster than <xref:System.Collections.Concurrent.ConcurrentQueue%601> on computers that have multiple cores.  \n  \n When processing time is around 500 FLOPS (floating point operations) or more, then the two-thread rule does not apply to <xref:System.Collections.Concurrent.ConcurrentQueue%601>, which then has very good scalability. <xref:System.Collections.Generic.Queue%601> does not scale well in this scenario.  \n  \n In mixed producer-consumer scenarios, when the processing time is very small, a <xref:System.Collections.Generic.Queue%601> that has an external lock scales better than <xref:System.Collections.Concurrent.ConcurrentQueue%601> does. However, when processing time is around 500 FLOPS or more, then the <xref:System.Collections.Concurrent.ConcurrentQueue%601> scales better.  \n  \n## ConcurrentStack vs. Stack  \n In pure producer-consumer scenarios, when processing time is very small, then <xref:System.Collections.Concurrent.ConcurrentStack%601?displayProperty=nameWithType> and <xref:System.Collections.Generic.Stack%601?displayProperty=nameWithType> that has an external lock will probably perform about the same with one dedicated pushing thread and one dedicated popping thread. However, as the number of threads increases, both types slow down because of increased contention, and <xref:System.Collections.Generic.Stack%601> might perform better than <xref:System.Collections.Concurrent.ConcurrentStack%601>. When processing time is around 500 FLOPS or more, then both types scale at about the same rate.  \n  \n In mixed producer-consumer scenarios, <xref:System.Collections.Concurrent.ConcurrentStack%601> is faster for both small and large workloads.  \n  \n The use of the <xref:System.Collections.Concurrent.ConcurrentStack%601.PushRange%2A> and <xref:System.Collections.Concurrent.ConcurrentStack%601.TryPopRange%2A> may greatly speed up access times.  \n  \n## ConcurrentDictionary vs. Dictionary  \n In general, use a <xref:System.Collections.Concurrent.ConcurrentDictionary%602?displayProperty=nameWithType> in any scenario where you are adding and updating keys or values concurrently from multiple threads. In scenarios that involve frequent updates and relatively few reads, the <xref:System.Collections.Concurrent.ConcurrentDictionary%602> generally offers modest benefits. In scenarios that involve many reads and many updates, the <xref:System.Collections.Concurrent.ConcurrentDictionary%602> generally is significantly faster on computers that have any number of cores.  \n  \n In scenarios that involve frequent updates, you can increase the degree of concurrency in the <xref:System.Collections.Concurrent.ConcurrentDictionary%602> and then measure to see whether performance increases on computers that have more cores. If you change the concurrency level, avoid global operations as much as possible.  \n  \n If you are only reading key or values, the <xref:System.Collections.Generic.Dictionary%602> is faster because no synchronization is required if the dictionary is not being modified by any threads.  \n  \n## ConcurrentBag  \n In pure producer-consumer scenarios, <xref:System.Collections.Concurrent.ConcurrentBag%601?displayProperty=nameWithType> will probably perform more slowly than the other concurrent collection types.  \n  \n In mixed producer-consumer scenarios, <xref:System.Collections.Concurrent.ConcurrentBag%601> is generally much faster and more scalable than any other concurrent collection type for both large and small workloads.  \n  \n## BlockingCollection  \n When bounding and blocking semantics are required, <xref:System.Collections.Concurrent.BlockingCollection%601?displayProperty=nameWithType> will probably perform faster than any custom implementation. It also supports rich cancellation, enumeration, and exception handling.  \n  \n## See also\n\n- <xref:System.Collections.Concurrent?displayProperty=nameWithType>\n- [Thread-Safe Collections](../../../../docs/standard/collections/thread-safe/index.md)\n- [Parallel Programming](../../../../docs/standard/parallel-programming/index.md)\n","nodes":[{"pos":[4,257],"embed":true,"restype":"x-metadata","content":"title: \"When to Use a Thread-Safe Collection\"\nms.date: \"03/30/2017\"\nms.technology: dotnet-standard\nhelpviewer_keywords: \n  - \"thread-safe collections, when to upgrade\"\nms.assetid: a9babe97-e457-4ff3-b528-a1bc940d5320\nauthor: \"mairaw\"\nms.author: \"mairaw\"","nodes":[{"content":"When to Use a Thread-Safe Collection","nodes":[{"pos":[0,36],"content":"When to Use a Thread-Safe Collection","nodes":[{"content":"When to Use a Thread-Safe Collection","pos":[0,36]}]}],"path":["title"],"nosxs":false}],"yml":true},{"pos":[264,300],"content":"When to Use a Thread-Safe Collection","linkify":"When to Use a Thread-Safe Collection","nodes":[{"content":"When to Use a Thread-Safe Collection","pos":[0,36]}]},{"content":"The <ph id=\"ph1\">[!INCLUDE[net_v40_long](../../../../includes/net-v40-long-md.md)]</ph> introduces five new collection types that are specially designed to support multi-threaded add and remove operations.","pos":[301,488],"source":"The [!INCLUDE[net_v40_long](../../../../includes/net-v40-long-md.md)] introduces five new collection types that are specially designed to support multi-threaded add and remove operations."},{"content":"To achieve thread-safety, these new types use various kinds of efficient locking and lock-free synchronization mechanisms.","pos":[489,611]},{"content":"Synchronization adds overhead to an operation.","pos":[612,658]},{"content":"The amount of overhead depends on the kind of synchronization that is used, the kind of operations that are performed, and other factors such as the number of threads that are trying to concurrently access the collection.","pos":[659,880]},{"content":"In some scenarios, synchronization overhead is negligible and enables the multi-threaded type to perform significantly faster and scale far better than its non-thread-safe equivalent when protected by an external lock.","pos":[887,1105]},{"content":"In other scenarios, the overhead can cause the thread-safe type to perform and scale about the same or even more slowly than the externally-locked, non-thread-safe version of the type.","pos":[1106,1290]},{"content":"The following sections provide general guidance about when to use a thread-safe collection versus its non-thread-safe equivalent that has a user-provided lock around its read and write operations.","pos":[1297,1493]},{"content":"Because performance may vary depending on many factors, the guidance is not specific and is not necessarily valid in all circumstances.","pos":[1494,1629]},{"content":"If performance is very important, then the best way to determine which collection type to use is to measure performance based on representative computer configurations and loads.","pos":[1630,1808]},{"content":"This document uses the following terms:","pos":[1809,1848]},{"content":"<bpt id=\"p1\">*</bpt>Pure producer-consumer scenario<ept id=\"p1\">*</ept>","pos":[1855,1888],"source":"*Pure producer-consumer scenario*"},{"content":"Any given thread is either adding or removing elements, but not both.","pos":[1892,1961]},{"content":"<bpt id=\"p1\">*</bpt>Mixed producer-consumer scenario<ept id=\"p1\">*</ept>","pos":[1968,2002],"source":"*Mixed producer-consumer scenario*"},{"content":"Any given thread is both adding and removing elements.","pos":[2006,2060]},{"content":"<bpt id=\"p1\">*</bpt>Speedup<ept id=\"p1\">*</ept>","pos":[2067,2076],"source":"*Speedup*"},{"content":"Faster algorithmic performance relative to another type in the same scenario.","pos":[2080,2157]},{"content":"<bpt id=\"p1\">*</bpt>Scalability<ept id=\"p1\">*</ept>","pos":[2164,2177],"source":"*Scalability*"},{"content":"The increase in performance that is proportional to the number of cores on the computer.","pos":[2181,2269]},{"content":"An algorithm that scales performs faster on eight cores than it does on two cores.","pos":[2270,2352]},{"pos":[2361,2392],"content":"ConcurrentQueue(T) vs. Queue(T)","linkify":"ConcurrentQueue(T) vs. Queue(T)","nodes":[{"content":"ConcurrentQueue(T) vs. Queue(T)","pos":[0,31]}]},{"content":"In pure producer-consumer scenarios, where the processing time for each element is very small (a few instructions), then <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentQueue%601?displayProperty=nameWithType&gt;</ph> can offer modest performance benefits over a <ph id=\"ph2\">&lt;xref:System.Collections.Generic.Queue%601?displayProperty=nameWithType&gt;</ph> that has an external lock.","pos":[2396,2747],"source":"In pure producer-consumer scenarios, where the processing time for each element is very small (a few instructions), then <xref:System.Collections.Concurrent.ConcurrentQueue%601?displayProperty=nameWithType> can offer modest performance benefits over a <xref:System.Collections.Generic.Queue%601?displayProperty=nameWithType> that has an external lock."},{"content":"In this scenario, <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentQueue%601&gt;</ph> performs best when one dedicated thread is queuing and one dedicated thread is de-queuing.","pos":[2748,2913],"source":" In this scenario, <xref:System.Collections.Concurrent.ConcurrentQueue%601> performs best when one dedicated thread is queuing and one dedicated thread is de-queuing."},{"content":"If you do not enforce this rule, then <ph id=\"ph1\">&lt;xref:System.Collections.Generic.Queue%601&gt;</ph> might even perform slightly faster than <ph id=\"ph2\">&lt;xref:System.Collections.Concurrent.ConcurrentQueue%601&gt;</ph> on computers that have multiple cores.","pos":[2914,3131],"source":" If you do not enforce this rule, then <xref:System.Collections.Generic.Queue%601> might even perform slightly faster than <xref:System.Collections.Concurrent.ConcurrentQueue%601> on computers that have multiple cores."},{"content":"When processing time is around 500 FLOPS (floating point operations) or more, then the two-thread rule does not apply to <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentQueue%601&gt;</ph>, which then has very good scalability.","pos":[3138,3354],"source":"When processing time is around 500 FLOPS (floating point operations) or more, then the two-thread rule does not apply to <xref:System.Collections.Concurrent.ConcurrentQueue%601>, which then has very good scalability."},{"content":"<ph id=\"ph1\">&lt;xref:System.Collections.Generic.Queue%601&gt;</ph> does not scale well in this scenario.","pos":[3355,3436],"source":"<xref:System.Collections.Generic.Queue%601> does not scale well in this scenario."},{"content":"In mixed producer-consumer scenarios, when the processing time is very small, a <ph id=\"ph1\">&lt;xref:System.Collections.Generic.Queue%601&gt;</ph> that has an external lock scales better than <ph id=\"ph2\">&lt;xref:System.Collections.Concurrent.ConcurrentQueue%601&gt;</ph> does.","pos":[3443,3674],"source":"In mixed producer-consumer scenarios, when the processing time is very small, a <xref:System.Collections.Generic.Queue%601> that has an external lock scales better than <xref:System.Collections.Concurrent.ConcurrentQueue%601> does."},{"content":"However, when processing time is around 500 FLOPS or more, then the <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentQueue%601&gt;</ph> scales better.","pos":[3675,3814],"source":" However, when processing time is around 500 FLOPS or more, then the <xref:System.Collections.Concurrent.ConcurrentQueue%601> scales better."},{"pos":[3823,3848],"content":"ConcurrentStack vs. Stack","linkify":"ConcurrentStack vs. Stack","nodes":[{"content":"ConcurrentStack vs. Stack","pos":[0,25]}]},{"content":"In pure producer-consumer scenarios, when processing time is very small, then <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentStack%601?displayProperty=nameWithType&gt;</ph> and <ph id=\"ph2\">&lt;xref:System.Collections.Generic.Stack%601?displayProperty=nameWithType&gt;</ph> that has an external lock will probably perform about the same with one dedicated pushing thread and one dedicated popping thread.","pos":[3852,4223],"source":"In pure producer-consumer scenarios, when processing time is very small, then <xref:System.Collections.Concurrent.ConcurrentStack%601?displayProperty=nameWithType> and <xref:System.Collections.Generic.Stack%601?displayProperty=nameWithType> that has an external lock will probably perform about the same with one dedicated pushing thread and one dedicated popping thread."},{"content":"However, as the number of threads increases, both types slow down because of increased contention, and <ph id=\"ph1\">&lt;xref:System.Collections.Generic.Stack%601&gt;</ph> might perform better than <ph id=\"ph2\">&lt;xref:System.Collections.Concurrent.ConcurrentStack%601&gt;</ph>.","pos":[4224,4454],"source":" However, as the number of threads increases, both types slow down because of increased contention, and <xref:System.Collections.Generic.Stack%601> might perform better than <xref:System.Collections.Concurrent.ConcurrentStack%601>."},{"content":"When processing time is around 500 FLOPS or more, then both types scale at about the same rate.","pos":[4455,4550]},{"pos":[4557,4697],"content":"In mixed producer-consumer scenarios, <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentStack%601&gt;</ph> is faster for both small and large workloads.","source":"In mixed producer-consumer scenarios, <xref:System.Collections.Concurrent.ConcurrentStack%601> is faster for both small and large workloads."},{"pos":[4704,4899],"content":"The use of the <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentStack%601.PushRange%2A&gt;</ph> and <ph id=\"ph2\">&lt;xref:System.Collections.Concurrent.ConcurrentStack%601.TryPopRange%2A&gt;</ph> may greatly speed up access times.","source":"The use of the <xref:System.Collections.Concurrent.ConcurrentStack%601.PushRange%2A> and <xref:System.Collections.Concurrent.ConcurrentStack%601.TryPopRange%2A> may greatly speed up access times."},{"pos":[4908,4943],"content":"ConcurrentDictionary vs. Dictionary","linkify":"ConcurrentDictionary vs. Dictionary","nodes":[{"content":"ConcurrentDictionary vs. Dictionary","pos":[0,35]}]},{"content":"In general, use a <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentDictionary%602?displayProperty=nameWithType&gt;</ph> in any scenario where you are adding and updating keys or values concurrently from multiple threads.","pos":[4947,5156],"source":"In general, use a <xref:System.Collections.Concurrent.ConcurrentDictionary%602?displayProperty=nameWithType> in any scenario where you are adding and updating keys or values concurrently from multiple threads."},{"content":"In scenarios that involve frequent updates and relatively few reads, the <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentDictionary%602&gt;</ph> generally offers modest benefits.","pos":[5157,5325],"source":" In scenarios that involve frequent updates and relatively few reads, the <xref:System.Collections.Concurrent.ConcurrentDictionary%602> generally offers modest benefits."},{"content":"In scenarios that involve many reads and many updates, the <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentDictionary%602&gt;</ph> generally is significantly faster on computers that have any number of cores.","pos":[5326,5524],"source":" In scenarios that involve many reads and many updates, the <xref:System.Collections.Concurrent.ConcurrentDictionary%602> generally is significantly faster on computers that have any number of cores."},{"content":"In scenarios that involve frequent updates, you can increase the degree of concurrency in the <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentDictionary%602&gt;</ph> and then measure to see whether performance increases on computers that have more cores.","pos":[5531,5775],"source":"In scenarios that involve frequent updates, you can increase the degree of concurrency in the <xref:System.Collections.Concurrent.ConcurrentDictionary%602> and then measure to see whether performance increases on computers that have more cores."},{"content":"If you change the concurrency level, avoid global operations as much as possible.","pos":[5776,5857]},{"pos":[5864,6060],"content":"If you are only reading key or values, the <ph id=\"ph1\">&lt;xref:System.Collections.Generic.Dictionary%602&gt;</ph> is faster because no synchronization is required if the dictionary is not being modified by any threads.","source":"If you are only reading key or values, the <xref:System.Collections.Generic.Dictionary%602> is faster because no synchronization is required if the dictionary is not being modified by any threads."},{"pos":[6069,6082],"content":"ConcurrentBag","linkify":"ConcurrentBag","nodes":[{"content":"ConcurrentBag","pos":[0,13]}]},{"pos":[6086,6284],"content":"In pure producer-consumer scenarios, <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentBag%601?displayProperty=nameWithType&gt;</ph> will probably perform more slowly than the other concurrent collection types.","source":"In pure producer-consumer scenarios, <xref:System.Collections.Concurrent.ConcurrentBag%601?displayProperty=nameWithType> will probably perform more slowly than the other concurrent collection types."},{"pos":[6291,6504],"content":"In mixed producer-consumer scenarios, <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.ConcurrentBag%601&gt;</ph> is generally much faster and more scalable than any other concurrent collection type for both large and small workloads.","source":"In mixed producer-consumer scenarios, <xref:System.Collections.Concurrent.ConcurrentBag%601> is generally much faster and more scalable than any other concurrent collection type for both large and small workloads."},{"pos":[6513,6531],"content":"BlockingCollection","linkify":"BlockingCollection","nodes":[{"content":"BlockingCollection","pos":[0,18]}]},{"content":"When bounding and blocking semantics are required, <ph id=\"ph1\">&lt;xref:System.Collections.Concurrent.BlockingCollection%601?displayProperty=nameWithType&gt;</ph> will probably perform faster than any custom implementation.","pos":[6535,6735],"source":"When bounding and blocking semantics are required, <xref:System.Collections.Concurrent.BlockingCollection%601?displayProperty=nameWithType> will probably perform faster than any custom implementation."},{"content":"It also supports rich cancellation, enumeration, and exception handling.","pos":[6736,6808]},{"pos":[6817,6825],"content":"See also","linkify":"See also","nodes":[{"content":"See also","pos":[0,8]}]},{"pos":[6897,6982],"content":"<bpt id=\"p1\">[</bpt>Thread-Safe Collections<ept id=\"p1\">](../../../../docs/standard/collections/thread-safe/index.md)</ept>","source":"[Thread-Safe Collections](../../../../docs/standard/collections/thread-safe/index.md)"},{"pos":[6985,7064],"content":"<bpt id=\"p1\">[</bpt>Parallel Programming<ept id=\"p1\">](../../../../docs/standard/parallel-programming/index.md)</ept>","source":"[Parallel Programming](../../../../docs/standard/parallel-programming/index.md)"}]}